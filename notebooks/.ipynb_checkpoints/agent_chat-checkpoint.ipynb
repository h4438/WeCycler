{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b0d1e-d81b-40ad-bb02-ab09afc93170",
   "metadata": {},
   "source": [
    "# Agent chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d158db71-07c8-4eab-8781-9f6865365fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing at vechai\n",
      "AI21 ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.setup import trace_ai21\n",
    "MODEL = trace_ai21('vechai')\n",
    "\n",
    "\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.chains.assess_usage import build_assess_usage_tool\n",
    "from botcore.chains.pros_cons import build_pros_cons_tool\n",
    "\n",
    "\n",
    "class AgentBot:\n",
    "\n",
    "    def __init__(self, model: BaseLLM, memory):\n",
    "        tools = self.load_tools(model, memory)\n",
    "        self.agent = initialize_agent(tools, model,\\\n",
    "                                      agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\\n",
    "                                      verbose=True, return_intermediate_steps=True)\n",
    "        print(\"Agent is ready\")\n",
    "        \n",
    "        \n",
    "    def load_tools(self, model, memory):\n",
    "        tools = [build_assess_usage_tool(model,memory),\n",
    "                 build_pros_cons_tool(model,memory)]\n",
    "        return tools\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f66cad5-4557-4a53-96f6-fefd09c17a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botcore.utils.memory_utils import QAMemory\n",
    "data = {\n",
    "  \"title\": \"Old phone\",\n",
    "  \"features\": [\n",
    "    \"What is the screen size? 2.8 inches\",\n",
    "    \"What is the RAM size? 512 MB\",\n",
    "    \"What is the storage capacity? 4 GB\",\n",
    "    \"What is the battery capacity? 1500 mAh\",\n",
    "    \"Is there any malfunction or defect? yes\",\n",
    "    \"What is the current physical condition of the product? excellent\",\n",
    "    \"Is the product still under warranty? yes\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "ques = [i.split(\"?\")[0] for i in data['features']]\n",
    "ans = [i.split(\"?\")[1] for i in data['features']]\n",
    "qa_mem = QAMemory('question')\n",
    "qa_mem.load_qa_to_memory(ques, ans)\n",
    "agent = AgentBot(MODEL, qa_mem.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3990d65-f539-4d5b-bb0f-f87b9232f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should consider if the product is recyclable\n",
      "Action: assess_usage\n",
      "Action Input: is the product recyclable\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a secondhand dealer and assessing the user's product. Based on your questions and user answers from the chat history.\n",
      " AI: What is the screen size\n",
      "Human:  2.8 inches\n",
      "AI: What is the RAM size\n",
      "Human:  512 MB\n",
      "AI: What is the storage capacity\n",
      "Human:  4 GB\n",
      "AI: What is the battery capacity\n",
      "Human:  1500 mAh\n",
      "AI: Is there any malfunction or defect\n",
      "Human:  yes\n",
      "AI: What is the current physical condition of the product\n",
      "Human:  excellent\n",
      "AI: Is the product still under warranty\n",
      "Human:  yes\n",
      "Human: product\n",
      "AI: \n",
      " Answer:\n",
      "{\n",
      " \"pros\": [\n",
      "  \"excellent physical condition\",\n",
      "  \"still under warranty\"\n",
      " ],\n",
      " \"cons\": [\n",
      "  \"malfunction\",\n",
      "  \"low RAM\",\n",
      "  \"low storage capacity\",\n",
      "  \"low battery capacity\"\n",
      " ],\n",
      " \"overview\": \"The product has several drawbacks, but its overall physical condition is excellent and it is still under warranty.\"\n",
      "}\n",
      "Human: is the product recyclable\n",
      "AI: \n",
      "{\n",
      " \"useable\": \"yes\",\n",
      " \"reason\": \"The product is made of recyclable materials.\",\n",
      " \"function\": \"The product can function well.\"\n",
      "}\n",
      " Please give your best answer for the given question from the user.\n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"useable\": string  // Is the given product still useable.\n",
      "\t\"reason\": string  // A reason why the product is useable or not useable.\n",
      "\t\"function\": string  // Assess how well the given product still can function.\n",
      "}\n",
      "```\n",
      " Question: is the product recyclable.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "{\n",
      " \"useable\": \"yes\",\n",
      " \"reason\": \"The product is made of recyclable materials.\",\n",
      " \"function\": \"The product can function well.\"\n",
      "}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know if the product is recyclable\n",
      "Final Answer: yes\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How can I recycle my product', 'output': 'yes'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = agent.agent(\"How can I recycle my product\")\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
